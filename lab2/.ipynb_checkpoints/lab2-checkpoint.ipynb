{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2: Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification is one of the most frequent applications of machine learning. In this workshop, your two goals are to work through the entire machine learning pipeline (though the data is preprocessed) and compare different supervised methods. There will be little driver code for this workshop, as comfort with implementing the steps of the machine learning pipeline is crucial within all domains. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import libraries - look at the last workshop if you don't remember the 3 most essential libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the file \"spambase.csv\" as a dataframe, and display the first 5 rows to examine the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each row of the spambase dataset is an email. The features are obtained by taking the frequency (which is normalized on email length) of certain words. Intuitively, emails containing words like \"free\" are likely to be spam emails, and using this feature representation we capture some of the important elements of the email's content. The label for the dataset is the binary \"is_spam\" column, which is 1 for spam emails and 0 for real emails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split the dataframe into features and label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split the (features, labels) set into training and testing sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now fit 3 different ML models to see which one does the best. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import logistic regression function from sklearn and create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit model on training set and predict on test features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate classification models, 2 common methods are zero-one-loss and confusion matrix. Zero-one-loss is the most basic and intuitive way to evaluate classification - this error is just the fraction of incorrectly predicted labels, so a zero-one-loss of 0 is optimal.\n",
    "\n",
    "One issue with zero-one-loss is that it doesn't distinguish between false positives and false negatives. The confusion matrix provides more information by showing how many times each label was predicted for elements of each true label. Documentation is given on the sklearn reference. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# display zero-one-loss and confusion matrix (importing from sklearn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2: SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import SVM function from sklearn and create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# display confusion matrix and zero-one-loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3: Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import decision tree function from sklearn and create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# display confusion matrix and zero-one-loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You've seen how some of the most common vanilla classification methods have performed on the data. However, there are countless ways to build upon these foundational methods to create more powerful models. Your challenge is to read up on some advanced classification methods to get the highest possible predictive accuracy on the test set. \n",
    "\n",
    "Some methods that build on top of decision trees and SVMs are different kernel functions for SVMs, gradient boosted trees, and random forests. Other classification methods that we haven't discussed are neural networks and Bayesian models. All of these methods are provided in Scikit-learn and documented [here](http://scikit-learn.org/stable/supervised_learning.html#supervised-learning). Read up on and try out the models that seem interesting or suitable for this problem, and try to get the highest accuracy out of all the teams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# repeat steps outlined above on different models to get the highest possible accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
