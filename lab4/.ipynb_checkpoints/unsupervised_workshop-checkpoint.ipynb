{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Means Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Clustering is a technique for finding similarity groups in a data, called clusters. It attempts to group points in your dataset together by similarity. Clustering is considered an unsupervised learning, since you don’t have prescribed labels in the data and no class values denoting a priori grouping of the data instances are given. Today we'll try running one of the most famous clustering algorithms — K-means — on a test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "To run a k-means algorithm, you have to randomly initialize points called the cluster centroids. \n",
    "\n",
    "There are two steps to K-means: cluster assignment and centroid update. In the former step, the algorithm goes through each of the data points\n",
    "and assigns each one to the cluster with the closest centroid. The latter step moves the centroids to the average of the points within the cluster it represents. We do this until there is no change in the clusters (or possibly until some other stopping condition is met). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets try out the sklearn implementation of kmeans. First we'll import libraries and the dataset we'll be looking at today. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named matplotlib.pyplot",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-377574a570c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named matplotlib.pyplot"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.cluster import KMeans\n",
    "import sklearn.metrics as sm\n",
    " \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    " \n",
    "%matplotlib inline\n",
    "\n",
    "# We'll use the iris dataset, a small real world dataset that comes with sklearn\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "# We'll store these input values as a Pandas Dataframe\n",
    "x = pd.DataFrame(iris.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try visualizing iris by printing things out.  Notice that our array in iris.data has four columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Using the Pandas Dataframe we made in the previous step, set the column names to their proper values.\n",
    "x.columns = \"fill this in\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: now that our inputs are all set, we'll store the target values as a Pandas Dataframe too\n",
    "y = pd.DataFrame(\"use the previous cell as a model to fill this in\")\n",
    "y.columns = [\"fill this in\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that while we have class labels for the dataset, the key distinction that makes the clustering method unsupervised is that we aren't training on these labels - instead of trying to construct a function from the feature space to the label space, we are trying to find statistical structure within our feature space. The labels are only used in this example to compare the clusters we find to the actual classes to show the power of the clustering method. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can plot our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, set the plot's size\n",
    "plt.figure(figsize=(14,7))\n",
    "\n",
    "# Make a colormap\n",
    "colormap = np.array(['red', 'lime', 'black'])\n",
    " \n",
    "# TODO: now lets plot Sepal values\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(\"fill this in to plot the proper inputs for sepal\", c=colormap[\"fill this in with the output\"], s=40)\n",
    "plt.title('Sepal')\n",
    "\n",
    "# TODO: do the same thing for Petal values\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(\"fill this in with the proper inputs for Petal\", c=colormap[\"fill this in with the output\"], s=40)\n",
    "plt.title('Petal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've visualized the data, let's try clustering it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: fill in parameters for sklearn kmeans function\n",
    "model = KMeans(n_clusters=\"based on your prior plots, what number of clusters do you think would be appropriate?\")\n",
    "model.fit(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can view the results of kmeans. This is what it decided for each point. So basically it assigns each point a number: 0, 1, or 2, depending on which cluster it goes under"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets plot the real classes against the predicted classes our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we are plotting the Petal Length and Width\n",
    "plt.figure(figsize=(14,7))\n",
    " \n",
    "# Create a colormap\n",
    "colormap = np.array(['red', 'lime', 'black'])\n",
    " \n",
    "# TODO: Plot Original\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(\"fill this in\", s=40)\n",
    "plt.title('Actual')\n",
    " \n",
    "# TODO: Plot Models\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(\"fill this in\", s=40)\n",
    "plt.title('K Mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait a second! The colors don't match up.  The green points in our KMeans don't correspond to the green points in the actual classification, so the data isn't assigned the proper value.  To fix it, we convert all the 1s to 0s and all the 0s to 1s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predY = np.choose(model.labels_, [1, 0, 2]).astype(np.int64)\n",
    "print (model.labels_)\n",
    "print (predY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the data and see if we labeled things correctly now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the size of the plot\n",
    "plt.figure(figsize=(14,7))\n",
    " \n",
    "# Create a colormap\n",
    "colormap = np.array(['red', 'lime', 'black'])\n",
    " \n",
    "# TODO: Plot Actual\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(x.Petal_Length, x.Petal_Width, c=colormap[y.Targets], s=40)\n",
    "plt.title('Actual')\n",
    " \n",
    "# TODO: Plot Fixed Prediction\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(x.Petal_Length, x.Petal_Width, c=colormap[\"what should this be?\"], s=40)\n",
    "plt.title('K Mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's see how well we did\n",
    "sm.accuracy_score(y, predY)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
